library(tidyverse)
library(tidymodels)
#install_keras()
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
install.packages("tensorflow")
library(keras)
library(tidyverse)
library(tidymodels)
library(reticulate)
path_to_python <- install_python()
virtualenv_create("r-reticulate", python = path_to_python)
library(keras)
library(tidyverse)
library(tidymodels)
library(tensorflow)
install_tensorflow(envname = "r-reticulate")
library(keras)
library(tidyverse)
library(tidymodels)
install.packages("keras")
library(keras)
install_keras(envname = "r-reticulate")
install.packages("keras")
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
library(keras)
library(tidyverse)
library(tidymodels)
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
install.packages("tensorflow")
install.packages("tensorflow")
library(reticulate)
path_to_python <- install_python()
virtualenv_create("r-reticulate", python = path_to_python)
library(tensorflow)
install_tensorflow(envname = "r-reticulate")
install.packages("keras")
library(keras)
install_keras(envname = "r-reticulate")
library(keras)
library(tidyverse)
library(tidymodels)
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
Y
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
install.packages("tensorflow")
library(reticulate)
path_to_python <- install_python()
library(reticulate)
path_to_python <- install_python()
install.packages("tensorflow")
library(reticulate)
path_to_python <- install_python()
install.packages(keras)
library(keras)
library(tidyverse)
library(tidymodels)
library(keras)
install_keras(envname = "r-reticulate")
Y
library(tensorflow)
path_to_python <- install_python()
library(reticulate)
path_to_python <- install_python()
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
library(keras)
library(tidyverse)
library(tidymodels)
df <- read_csv("creditcard.csv", show_col_types = FALSE)
library(tensorflow)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/download?datasetVersionNumber=3", show_col_types = FALSE)
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/download?datasetVersionNumber=3", show_col_types = FALSE)
summary(df)
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
library(keras)
library(tidyverse)
library(tidymodels)
# https://www.kaggle.com/mlg-ulb/creditcardfraud
# File is too big for github
df <- read_csv("creditcard.csv", show_col_types = FALSE)
summary(df)
df_Class <-
df %>% mutate(Class = if_else(Class == 1, "Fraudulent", "Trustworthy") %>% as.factor())
#summary(df_Class)
set.seed(0)
df_split <- initial_split(df_Class, strata = Class)
train_data <- training(df_split)
test_data <- testing(df_split)
#Statistical Normalization for Neural Network
df_Scale <-
recipe(Class ~ ., data = train_data) %>% step_range(all_predictors())
train_data <- df_Scale %>% prep() %>% bake(train_data)
test_data <- df_Scale %>% prep() %>% bake(test_data)
#summary(train_data)
df_fraud <-
train_data %>% filter(Class == "Fraudulent") %>% select(-Class) %>% as.matrix()
df_trust <-
train_data %>% filter(Class == "Trustworthy") %>% select(-Class) %>% as.matrix()
AutoEncoder <- keras_model_sequential()
AutoEncoder %>%
layer_dense(
units = 15,
activation = 'relu',
input_shape = ncol(df_trust)
) %>%
layer_dense(units = 5, activation = 'relu') %>%
layer_dense(units = 15, activation = 'relu') %>%
layer_dense(units = ncol(df_trust))
AutoEncoder %>% compile(loss = "mean_squared_error", optimizer ="adam")
AutoEncoder_hist <-
AutoEncoder %>% fit(
x = df_trust,
y = df_trust,
epochs = 100,
batch_size = 32,
validation_split = .8,
options = callback_early_stopping(patience = 10)
)
pred_trust <- predict(AutoEncoder,df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
#head(pred_trust)
rowSums((pred_trust - pred_fraud)^2)
pred_trust <- predict(AutoEncoder, df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
#head(pred_trust)
tibble(total_sq_err = rowSums((pred_trust - pred_fraud)^2))
pred_trust <- predict(AutoEncoder, df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
head(pred_trust)
#tibble(total_sq_err = rowSums((pred_trust - pred_fraud)^2))
pred_trust <- predict(AutoEncoder, df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
#head(pred_trust)
tibble(total_sq_err = rowSums((pred_trust - df_trust)^2))
pred_trust <- predict(AutoEncoder, df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
#head(pred_trust)
summary(tibble(total_sq_err = rowSums((pred_trust - df_trust)^2)))
summary(tibble(total_sq_err = rowSums((pred_fraud - df_fraud)^2)))
pred_trust <- predict(AutoEncoder, df_trust)
pred_fraud <- predict(AutoEncoder, df_fraud)
#head(pred_trust)
summary(tibble(total_sq_err_trust = rowSums((pred_trust - df_trust)^2)))
summary(tibble(total_sq_err_fraud = rowSums((pred_fraud - df_fraud)^2)))
predict(Autoencoder, train_data %>% select(-Class))
predict(AutoEncoder, train_data %>% select(-Class))
rowSums((predict(AutoEncoder, train_data %>% select(-Class) %>% as.matrix() - train_data %>% select(-Class) %>% as.matrix())^2))
tiblle(error = rowSums((predict(AutoEncoder, train_data %>% select(-Class) %>% as.matrix() - train_data %>% select(-Class) %>% as.matrix())^2)))
tibble(error = rowSums((predict(AutoEncoder, train_data %>% select(-Class) %>% as.matrix() - train_data %>% select(-Class) %>% as.matrix())^2)))
data <-
tibble(error = rowSums((
predict(
AutoEncoder,
train_data %>% select(-Class) %>% as.matrix() - train_data %>% select(-Class) %>% as.matrix()
) ^ 2
)) %>% bind_cols(train_data %>% select(Class)))
data %>% group_by(Class) %>% summarise(mean = mean(error))
model_data <-
tibble(error = rowSums((
predict(autoencoder, train_data %>% select(-Class) %>% as.matrix()) - train_data %>% select(-Class) %>% as.matrix()
) ^ 2)) %>%
bind_cols(train_data %>% select(Class))
model_data <-
tibble(error = rowSums((
predict(AutoEncoder, train_data %>% select(-Class) %>% as.matrix()) - train_data %>% select(-Class) %>% as.matrix()
) ^ 2)) %>%
bind_cols(train_data %>% select(Class))
model_data %>% group_by(Class) %>% summarise(mean = mean(error))
anom_model <- logistic_reg(penalty = 0, mixture = 0) %>%
fit(Class ~ error, data = model_data)
predict(anom_model, model_data) %>%
bind_cols(model_data %>% select(Class)) %>%
conf_mat(truth = Class, estimate = .pred_class)
baseline_model <- logistic_reg(penalty = 0, mixture = 0) %>%
fit(Class ~ ., data = train_data)
predict(baseline_model, train_data) %>%
bind_cols(train_data %>% select(Class)) %>%
conf_mat(truth = Class, estimate = .pred_class)
eval_set <-
tibble(error = rowSums((
predict(autoencoder, test_data %>% select(-Class) %>% as.matrix()) - test_data %>% select(-Class) %>% as.matrix()
) ^ 2)) %>%
bind_cols(test_data %>% select(Class))
eval_set <-
tibble(error = rowSums((
predict(AutoEncoder, test_data %>% select(-Class) %>% as.matrix()) - test_data %>% select(-Class) %>% as.matrix()
) ^ 2)) %>%
bind_cols(test_data %>% select(Class))
predict(anom_model, eval_set) %>%
bind_cols(eval_set %>% select(Class)) %>%
conf_mat(truth = Class, estimate = .pred_class)
predict(baseline_model, test_data) %>%
bind_cols(test_data %>% select(Class)) %>%
conf_mat(truth = Class, estimate = .pred_class)
